{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tiny TextGrad Examples: Basic Prompt Optimization\n",
    "\n",
    "This notebook demonstrates how to use Tiny TextGrad to optimize a prompt for a given set of inputs. The prompt is optimized using a simple text loss function that focuses on clarity, accuracy, and handling of cases where the answer is not in the text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import dedent\n",
    "\n",
    "from tinytextgrad.llm import call_llm\n",
    "from tinytextgrad.prompt import (\n",
    "    optimize_prompt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-07-12 05:03:38.885\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtinytextgrad.ttg\u001b[0m:\u001b[36moptimize_text\u001b[0m:\u001b[36m165\u001b[0m - \u001b[34m\u001b[1m∇ 1. Current prompt:\n",
      "\n",
      "Given some text and a question, determine if the text\n",
      "contains the answer to the question\u001b[0m\n",
      "\u001b[32m2024-07-12 05:03:54.248\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtinytextgrad.ttg\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m152\u001b[0m - \u001b[34m\u001b[1m∇ Loss:\n",
      "\n",
      "### Prompt Evaluation\n",
      "\n",
      "#### Clarity\n",
      "The prompt is relatively clear in its instruction to determine if the given text contains the answer to the specified question. However, it could be slightly more explicit in stating that the response should be either \"Yes\" or \"No, the text does not contain the answer to the question.\"\n",
      "\n",
      "#### Specificity\n",
      "The prompt provides necessary details without being overly verbose, but it could benefit from more explicit guidance on the expected format of the response.\n",
      "\n",
      "#### Relevance\n",
      "All the information included in the prompt is pertinent to the task of assessing whether the text contains the answer to the question.\n",
      "\n",
      "#### Consistency\n",
      "The prompt does not contain any contradictory instructions. However, the results show some inconsistency in the output format (e.g., \"Yes\" vs. \"No, the text does not contain the answer to the question\").\n",
      "\n",
      "#### Actionability\n",
      "The prompt guides the AI towards producing a concrete, useful output. However, the format of the response should be standardized for better actionability.\n",
      "\n",
      "#### Output Quality\n",
      "The results are mostly effective in addressing the prompt's requirements but show some inconsistencies. For example:\n",
      "- \"The Earth orbits the Sun. Question: What does the Earth orbit?\" should indeed be \"Yes\".\n",
      "- \"Beethoven composed many symphonies. Question: Who composed the Fifth Symphony?\" should be \"No, the text does not contain the answer to the question\" since \"many symphonies\" is not specific to the Fifth Symphony.\n",
      "\n",
      "#### Output Consistency\n",
      "The results show inconsistencies, especially in the format of the responses and some inaccurate \"Yes\" answers.\n",
      "\n",
      "#### Efficiency\n",
      "The prompt achieves the desired outcome with minimal complexity, but the response format and accuracy need improvement for efficiency.\n",
      "\n",
      "### Handling of Cases Where the Answer is Not in the Text\n",
      "The prompt encourages the AI to state clearly when the information is not available, which is good. However, there are instances where it should have said \"No\" but didn't, indicating a need for clearer guidelines.\n",
      "\n",
      "### Suggestions for Improvement\n",
      "1. **Clarity**: Reword the prompt to explicitly state that the response should be \"Yes\" or \"No, the text does not contain the answer to the question.\"\n",
      "2. **Specificity**: Ensure the expected response format is consistent and clear.\n",
      "3. **Output Quality**: Add a guideline to ensure that the AI does not make assumptions and only says \"Yes\" if the answer is explicitly in the text.\n",
      "4. **Efficiency**: Standardize the response format to improve efficiency and reduce complexity.\n",
      "5. **Handling Missing Information**: Reinforce that the AI should not make up information and should clearly state when the text does not contain the answer.\n",
      "\n",
      "By addressing these points, the prompt can be made more robust and effective across different scenarios.\u001b[0m\n",
      "\u001b[32m2024-07-12 05:03:56.669\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtinytextgrad.ttg\u001b[0m:\u001b[36mbackward\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1m∇ Updated value:\n",
      "\n",
      "Given some text and a question, determine if the text contains the answer. Respond with either \"Yes\" or \"No, the text does not contain the answer.\"\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Final optimized TEXT_CONTAINS_ANSWER_PROMPT:\n",
      "Given some text and a question, determine if the text contains the answer. Respond with either \"Yes\" or \"No, the text does not contain the answer.\"\n"
     ]
    }
   ],
   "source": [
    "initial_prompt = dedent(\"\"\"\n",
    "Given some text and a question, determine if the text\n",
    "contains the answer to the question\n",
    "\"\"\").strip()\n",
    "\n",
    "inputs = [\n",
    "    \"Text: The cat is on the mat. Question: Where is the cat?\",\n",
    "    \"Text: The sky is blue. Question: What color is the grass?\",\n",
    "    \"Text: Paris is the capital of France. Question: What is the capital of Germany?\",\n",
    "    \"Text: The Earth orbits the Sun. Question: What does the Earth orbit?\",\n",
    "    \"Text: Water freezes at 0 degrees Celsius. Question: At what temperature does water boil?\",\n",
    "    \"Text: Beethoven composed many symphonies. Question: Who composed the Fifth Symphony?\",\n",
    "    \"Text: Elephants are the largest land animals. Question: What is the largest land animal?\",\n",
    "    \"Text: Shakespeare wrote 'Romeo and Juliet.' Question: Who wrote 'Hamlet'?\",\n",
    "    \"Text: Humans have 206 bones. Question: How many bones do humans have?\",\n",
    "    \"Text: Coffee is typically grown in tropical regions. Question: Where is coffee typically grown?\",\n",
    "]\n",
    "\n",
    "result = optimize_prompt(\n",
    "    initial_prompt,\n",
    "    \"gpt-3.5-turbo\",\n",
    "    \"gpt-4o\",\n",
    "    inputs,\n",
    "    num_iterations=1,\n",
    ")\n",
    "\n",
    "print(\"\\n\\nFinal optimized TEXT_CONTAINS_ANSWER_PROMPT:\")\n",
    "print(result.variable.value)\n",
    "\n",
    "TEXT_CONTAINS_ANSWER_PROMPT = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes\n",
      "No, the text does not contain the answer.\n",
      "No, the text does not contain the answer.\n",
      "Yes\n",
      "No, the text does not contain the answer.\n",
      "Yes\n",
      "Yes\n",
      "No, the text does not contain the answer.\n",
      "Yes\n",
      "Yes\n"
     ]
    }
   ],
   "source": [
    "for _input in inputs:\n",
    "    response = call_llm(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        prompt=TEXT_CONTAINS_ANSWER_PROMPT.variable.value,\n",
    "        prompt_input=_input,\n",
    "        temperature=0.7,\n",
    "        max_tokens=100,\n",
    "        top_p=0.95,\n",
    "        frequency_penalty=0,\n",
    "    )\n",
    "    print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
